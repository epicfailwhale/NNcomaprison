{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ec9c45",
   "metadata": {},
   "source": [
    "**Using PCA to compress images**\n",
    "https://www.askpython.com/python/examples/principal-component-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2624c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a95ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X , num_components):\n",
    "     \n",
    "    #Step-1\n",
    "    X_meaned = X - np.mean(X , axis = 0)\n",
    "    \n",
    "    #print('x mean', X_meaned)\n",
    "     \n",
    "    #Step-2 covariance matirx - gives the covariance between each pair of elements of a given random vector\n",
    "    # basically how much the data 'covaries' with each other along dimensions, around the centre\n",
    "    cov_mat = np.cov(X_meaned , rowvar = False)\n",
    "    \n",
    "    #print('cov mat', cov_mat)\n",
    "     \n",
    "    #Step-3\n",
    "    eigen_values , eigen_vectors = np.linalg.eigh(cov_mat)\n",
    "    # eigen vectors, v, are those that are along the same projection line following transformation\n",
    "    # ie. Av = yv\n",
    "    # eigen value is y, the scale of projection\n",
    "     \n",
    "    #Step-4\n",
    "    sorted_index = np.argsort(eigen_values)[::-1]\n",
    "    sorted_eigenvalue = eigen_values[sorted_index]\n",
    "    sorted_eigenvectors = eigen_vectors[:,sorted_index]\n",
    "    # sorting the eigen values in terms of their size\n",
    "    # largest eigen value corresponds to principal component with highest variability\n",
    "    # then sort the eigen vectors into the same order as well\n",
    "     \n",
    "    #Step-5\n",
    "    eigenvector_subset = sorted_eigenvectors[:,0:num_components]\n",
    "    # then take the first num_components of the eigen vectors ie. the number\n",
    "    # of principal components we are concerned with\n",
    "     \n",
    "    #Step-6\n",
    "    X_reduced = np.dot(eigenvector_subset.transpose() , X_meaned.transpose() ).transpose()\n",
    "    # input data shape is (dimension1, dimension2)\n",
    "    # output data shape (dimension1, num_components)\n",
    "    \n",
    "    #print('X_reduced', X_reduced)\n",
    "     \n",
    "    return X_reduced, sorted_eigenvectors, sorted_eigenvalue, X_meaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "646629a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavel\n",
      " 0     5\n",
      "1     0\n",
      "2     4\n",
      "3     1\n",
      "4     9\n",
      "     ..\n",
      "95    0\n",
      "96    7\n",
      "97    8\n",
      "98    3\n",
      "99    1\n",
      "Name: 0, Length: 100, dtype: int64\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "#prepare the data\n",
    "x = mnist_dataset[:][1]\n",
    "x_df = pd.DataFrame(x.numpy())\n",
    "\n",
    "#prepare the label - ie. the label of the data point\n",
    "label = mnist_dataset[:][0]\n",
    "# label_df = pd.DataFrame(label.numpy())\n",
    "print('lavel\\n', label)\n",
    "\n",
    " \n",
    "#Applying it to PCA function\n",
    "mat_reduced = PCA(x_df , 2)\n",
    "\n",
    "print(numpy.shape(mat_reduced[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbfc4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(image_vector, eigen_vectors, score, mean_vector):\n",
    "#      reconstruction(image,np.transpose(eig_vecs),score,mean_vector,i)\n",
    "# recontruct, get from (dimension1, num_components) back to (dimension1, 784)\n",
    "# dimension 1 number of pictures\n",
    "    recon = numpy.dot((eigen_vectors), score)\n",
    "    for i in range(len(recon)):\n",
    "        recon[i] += mean_vector[i]\n",
    "    \n",
    "#     print(recon)\n",
    "    return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f309754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "image = x_df.iloc[57]\n",
    "eig_vecs = mat_reduced[1]\n",
    "eig_values = mat_reduced[2]\n",
    "score = numpy.dot(eig_vecs, image)\n",
    "mean_vector = np.mean(x_df, axis = 0)\n",
    "\n",
    "\n",
    "recon = reconstruct(image,np.transpose(eig_vecs),score,mean_vector)\n",
    "print(numpy.shape(recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9de333f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2373e85d820>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "second_image = x_df.iloc[57].values.reshape([28,28])  # reshape it into square\n",
    "plt.imshow(second_image, cmap='gray_r')     # and present!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2caba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2373e8b0e50>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAYING ANY IMAGE - here using x ie. input data\n",
    "\n",
    "#           [the corresponding row number in the big training array]\n",
    "second_image = recon.reshape([28,28])  # reshape it into square\n",
    "plt.imshow(second_image, cmap='gray_r')     # and present!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f06ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file):\n",
    "        self.data_df = pandas.read_csv(csv_file, header=None)\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # image target (label)\n",
    "        label = self.data_df.iloc[index,0]\n",
    "        target = torch.zeros((10))\n",
    "        target[label] = 1.0\n",
    "        \n",
    "        # image data, normalised from 0-255 to 0-1\n",
    "        image_values = torch.FloatTensor(self.data_df.iloc[index,1:].values) / 255.0\n",
    "        \n",
    "        # return label, image data tensor and target tensor\n",
    "        return label, image_values, target\n",
    "    \n",
    "    def plot_image(self, index):\n",
    "        img = self.data_df.iloc[index,1:].values.reshape(28,28)\n",
    "        plt.title(\"label = \" + str(self.data_df.iloc[index,0]))\n",
    "        plt.imshow(img, interpolation='none', cmap='Blues')\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8a9894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(100,) <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9459db4a5fae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "mnist_dataset = MnistDataset('mnist_dataset/mnist_train_100.csv')\n",
    "# print(mnist_dataset[1][1])\n",
    "print(len(mnist_dataset))\n",
    "\n",
    "x = mnist_dataset[:][0]\n",
    "print(numpy.shape(x), type(x))\n",
    "x_df = pd.DataFrame(x.numpy())\n",
    "print(numpy.shape(x_df), type(x_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc7c0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lavel\n",
      " 0     5\n",
      "1     0\n",
      "2     4\n",
      "3     1\n",
      "4     9\n",
      "     ..\n",
      "95    0\n",
      "96    7\n",
      "97    8\n",
      "98    3\n",
      "99    1\n",
      "Name: 0, Length: 100, dtype: int64\n",
      "         PC1       PC2  0\n",
      "0  -1.245137 -1.595815  5\n",
      "1  -4.318578  1.712929  0\n",
      "2   0.899237  0.348863  4\n",
      "3   3.192519 -1.247315  1\n",
      "4   1.685397  1.938380  9\n",
      "..       ...       ... ..\n",
      "95 -6.047332  2.020016  0\n",
      "96  2.462806  0.995374  7\n",
      "97 -0.074811  0.300879  8\n",
      "98 -0.481279 -4.640902  3\n",
      "99  3.564169 -1.030985  1\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "(100, 3)\n",
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "mnist_dataset = MnistDataset('mnist_dataset/mnist_train_100.csv')\n",
    "\n",
    "# gonna attempt to do it the way we did before\n",
    "# firstline = list(range(0,785))\n",
    "# data = pd.read_csv('mnist_dataset/mnist_train_100.csv', names = firstline, index_col=False)\n",
    "\n",
    "\n",
    "#prepare the data\n",
    "x = mnist_dataset[:][1]\n",
    "x_df = pd.DataFrame(x.numpy())\n",
    "\n",
    "#prepare the label - ie. the label of the data point\n",
    "label = mnist_dataset[:][0]\n",
    "# label_df = pd.DataFrame(label.numpy())\n",
    "print('label\\n', label)\n",
    "\n",
    " \n",
    "#Applying it to PCA function\n",
    "mat_reduced = PCA(x_df , 2)\n",
    "\n",
    " \n",
    "#Creating a Pandas DataFrame of reduced Dataset\n",
    "principal_df = pd.DataFrame(mat_reduced , columns = ['PC1', 'PC2'])\n",
    "\n",
    "#print(principal_df)\n",
    " \n",
    "#Concat it with target variable to create a complete Dataset\n",
    "principal_df = pd.concat([principal_df , pd.DataFrame(target)] , axis = 1)\n",
    "# concat means concatenate - link things together in chain / series \n",
    "# ie. join together two datasets / arrays / lists\n",
    "# here join back the data with their label points\n",
    "\n",
    "print(principal_df)\n",
    "print(np.shape(principal_df))\n",
    "print(np.shape(x))\n",
    "\n",
    "\n",
    "\n",
    "# still need to turn it into a new picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ce6b3",
   "metadata": {},
   "source": [
    "https://training.incf.org/lesson/tutorial-3-dimensionality-reduction-and-reconstruction <br> good at explaining variance in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2288f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape (100, 784) <class 'pandas.core.frame.DataFrame'>\n",
      "            PC1          PC2  0\n",
      "0   -317.510084  -406.932771  5\n",
      "1  -1101.237389   436.796834  0\n",
      "2    229.305400    88.960092  4\n",
      "3    814.092262  -318.065225  1\n",
      "4    429.776153   494.286816  9\n",
      "..          ...          ... ..\n",
      "95 -1542.069632   515.104222  0\n",
      "96   628.015444   253.820285  7\n",
      "97   -19.076971    76.724241  8\n",
      "98  -122.726122 -1183.430040  3\n",
      "99   908.862994  -262.901175  1\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "(100, 3)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    " \n",
    "\n",
    "# gonna attempt to do it the way we did before\n",
    "firstline = list(range(0,785))\n",
    "data = pd.read_csv('mnist_dataset/mnist_train_100.csv', names = firstline, index_col=False)\n",
    "\n",
    "\n",
    "#prepare the data\n",
    "x = data.iloc[:,1:785]\n",
    "print('x shape', numpy.shape(x), type(x))\n",
    "\n",
    "\n",
    "#prepare the target - ie. the label of the data points\n",
    "target = data.iloc[:,0]\n",
    "# print('targ\\n', target)\n",
    "\n",
    " \n",
    "#Applying it to PCA function\n",
    "mat_reduced = PCA(x , 2)\n",
    "\n",
    " \n",
    "#Creating a Pandas DataFrame of reduced Dataset\n",
    "principal_df = pd.DataFrame(mat_reduced , columns = ['PC1', 'PC2'])\n",
    "# so, each of these columns reprsents where along the '2' dimensions \n",
    "# (vary dimensions according to how many PCAs there are) the image lies\n",
    "\n",
    "#print(principal_df)\n",
    " \n",
    "#Concat it with target variable to create a complete Dataset\n",
    "principal_df = pd.concat([principal_df , pd.DataFrame(target)] , axis = 1)\n",
    "# concat means concatenate - link things together in chain / series \n",
    "# ie. join together two datasets / arrays / lists\n",
    "# here join back the data with their label points\n",
    "\n",
    "print(principal_df)\n",
    "print(np.shape(principal_df))\n",
    "print(np.shape(x))\n",
    "\n",
    "\n",
    "\n",
    "# still need to turn it into a new picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "124643ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2373e63ba90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAYING ANY IMAGE - here using x ie. input data\n",
    "\n",
    "#           [the corresponding row number in the big training array]\n",
    "second_image = x_df.iloc[23].values.reshape([28,28])  # reshape it into square\n",
    "plt.imshow(second_image, cmap='gray_r')     # and present!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4e99ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-7a15e519b408>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprojected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# get the first projection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfirst_proj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprojected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# Make sure your first component is a column vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfirst_proj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_proj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "projected = pca.fit_transform(patches_reshaped.data)\n",
    "\n",
    "# First get your first component\n",
    "first_component = principal_df.PC1\n",
    "# Make sure your first component is a row vector\n",
    "# first_component = first_component.reshape(1,-1) \n",
    "\n",
    "projected = []\n",
    "# get the first projection \n",
    "first_proj = projected[:,0]\n",
    "# Make sure your first component is a column vector\n",
    "first_proj = first_proj.reshape(-1,1)\n",
    "# do inverse transform (No you have to add the mean as thse algorithm \n",
    "# works on zero mean data) \n",
    "recon_using_first_comp = np.dot(proj, first_component) + pca.mean_\n",
    "\n",
    "final_img = image.reconstruct_from_patches_2d(recon_using_first_comp.reshape(-1,25,25), grayscale_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9eee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(X, n, trans):\n",
    "    \n",
    "    \"\"\"\n",
    "    X is the original, n is the number of dimensions \n",
    "    \n",
    "    Creates a reconstruction of an input record, X, using the topmost (n) vectors from the\n",
    "    given transformation (trans)\n",
    "    \n",
    "    Note 1: In this dataset each record is the set of pixels in the image (flattened to \n",
    "    one row).\n",
    "    Note 2: X should be normalized before input.\n",
    "    \"\"\"\n",
    "    vectors = [trans.components_[n] * X[n] for n in range(0, n)]\n",
    "    # i THINK .components_[3] means you're splitting the data into 3 principal components.\n",
    "    # and trans.components_[3] means you're applying the 3 components onto the data trans\n",
    "    # trans is the result of sklearn given some random pca data i don't really know.\n",
    "    # okay i think trans is in fact just the formula for pca\n",
    "    # so i could just do the vector of pca values?\n",
    "    # components_ are mathematically the eigenvectors of the covariance matrix of the \n",
    "    # centered input matrix. This can be verified by using plain numpy.\n",
    "    \n",
    "    # Invert the PCA transformation.\n",
    "    ret = trans.inverse_transform(X)\n",
    "    \n",
    "    # This process results in non-normal noise on the margins of the data.\n",
    "    # We clip the results to fit in the [0, 1] interval.\n",
    "    ret[ret < 0] = 0\n",
    "    ret[ret > 1] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_norm is the original\n",
    "# x_norm_r is the reconstructed\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "sns.heatmap(X_norm[0, :].reshape(28, 28), cmap='gray_r',\n",
    "            ax=axarr[0])\n",
    "sns.heatmap(reconstruction(X_norm_r[0, :], 120, pca).reshape(28, 28), cmap='gray_r',\n",
    "            ax=axarr[1])\n",
    "axarr[0].set_aspect('equal')\n",
    "axarr[0].axis('off')\n",
    "axarr[1].set_aspect('equal')\n",
    "axarr[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3fafec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `red` for parameter `hue`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-1100279a5541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprincipal_df\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'PC1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'PC2'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'icefire'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# this just becomes a weird mess of dots.... do they mean anything maybe??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# they show the variation of data 'clumps' of each digit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mscatterplot\u001b[1;34m(x, y, hue, style, size, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ScatterPlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m     p = _ScatterPlotter(\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mx_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_bins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables, x_bins, y_bins, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend)\u001b[0m\n\u001b[0;32m    585\u001b[0m         )\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"long\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[0;32m    668\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `red` for parameter `hue`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "fig = plt.figure(figsize = (6,6))\n",
    "\n",
    "sb.scatterplot(data = principal_df , x = 'PC1',y = 'PC2' , hue = 'red', s = 60 , palette= 'icefire')\n",
    "# this just becomes a weird mess of dots.... do they mean anything maybe??\n",
    "# they show the variation of data 'clumps' of each digit\n",
    "\n",
    "principal_df()\n",
    "\n",
    "second_image = principal_df.iloc[1].values.reshape([28,28])\n",
    "plt.imshow(second_image, cmap='gray_r')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a56df14a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cv2' from 'IPython' (C:\\Users\\victo\\anaconda3\\lib\\site-packages\\IPython\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-15539d97a74e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Read RGB image into an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'car.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'cv2' from 'IPython' (C:\\Users\\victo\\anaconda3\\lib\\site-packages\\IPython\\__init__.py)"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
